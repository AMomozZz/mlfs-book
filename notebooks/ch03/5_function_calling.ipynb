{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "58c8d689",
   "metadata": {},
   "source": [
    "## <span style='color:#ff5f27'> üìù Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9a413f75",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor\n",
    "import hopsworks\n",
    "from functions.llm_chain import load_model, get_llm_chain, generate_response\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baddaef9",
   "metadata": {},
   "source": [
    "## <span style=\"color:#ff5f27;\"> üîÆ Connect to Hopsworks Feature Store </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dd9eb9ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected. Call `.close()` to terminate connection gracefully.\n",
      "\n",
      "Logged in to project, explore it here https://snurran.hops.works/p/8321\n",
      "Connected. Call `.close()` to terminate connection gracefully.\n"
     ]
    }
   ],
   "source": [
    "project = hopsworks.login()\n",
    "fs = project.get_feature_store() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f483ebb",
   "metadata": {},
   "source": [
    "## <span style=\"color:#ff5f27;\"> ‚öôÔ∏è Feature View Creation</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "07980bfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve feature groups\n",
    "air_quality_fg = fs.get_feature_group(\n",
    "    name='air_quality',\n",
    "    version=1,\n",
    ")\n",
    "weather_fg = fs.get_feature_group(\n",
    "    name='weather',\n",
    "    version=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "534e001d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select features for training data.\n",
    "selected_features = air_quality_fg.select(['date', 'pm25']).join(\n",
    "    weather_fg.select(['temperature_2m_mean', 'precipitation_sum', 'wind_speed_10m_max', 'wind_direction_10m_dominant']), \n",
    "    on=['city'],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e0a28636",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished: Reading data from Hopsworks, using ArrowFlight (1.25s) \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>pm25</th>\n",
       "      <th>temperature_2m_mean</th>\n",
       "      <th>precipitation_sum</th>\n",
       "      <th>wind_speed_10m_max</th>\n",
       "      <th>wind_direction_10m_dominant</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-10-04 00:00:00+00:00</td>\n",
       "      <td>13.0</td>\n",
       "      <td>10.587333</td>\n",
       "      <td>2.9</td>\n",
       "      <td>22.206486</td>\n",
       "      <td>248.656326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-10-05 00:00:00+00:00</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8.433167</td>\n",
       "      <td>2.6</td>\n",
       "      <td>16.595179</td>\n",
       "      <td>306.521240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017-10-06 00:00:00+00:00</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.247749</td>\n",
       "      <td>0.5</td>\n",
       "      <td>23.871555</td>\n",
       "      <td>320.408325</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        date  pm25  temperature_2m_mean  precipitation_sum  \\\n",
       "0  2017-10-04 00:00:00+00:00  13.0            10.587333                2.9   \n",
       "1  2017-10-05 00:00:00+00:00   9.0             8.433167                2.6   \n",
       "2  2017-10-06 00:00:00+00:00   8.0             8.247749                0.5   \n",
       "\n",
       "   wind_speed_10m_max  wind_direction_10m_dominant  \n",
       "0           22.206486                   248.656326  \n",
       "1           16.595179                   306.521240  \n",
       "2           23.871555                   320.408325  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get_or_create the 'air_quality_fv' feature view\n",
    "feature_view = fs.get_or_create_feature_view(\n",
    "    name='air_quality_fv',\n",
    "    version=2,\n",
    "    query=selected_features,\n",
    ")\n",
    "\n",
    "# Initialize batch scoring\n",
    "feature_view.init_batch_scoring(1)\n",
    "\n",
    "data, _ = feature_view.training_data()\n",
    "data.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ad925d6",
   "metadata": {},
   "source": [
    "## <span style=\"color:#ff5f27;\">ü™ù Retrieve AirQuality Model from Model Registry</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5ba0d5f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected. Call `.close()` to terminate connection gracefully.\n",
      "Downloading model artifact (1 dirs, 6 files)... DONE\r"
     ]
    }
   ],
   "source": [
    "# Retrieve the model registry\n",
    "mr = project.get_model_registry()\n",
    "\n",
    "# Retrieve the 'air_quality_xgboost_model' from the model registry\n",
    "retrieved_model = mr.get_model(\n",
    "    name=\"air_quality_xgboost_model\",\n",
    "    version=1,\n",
    ")\n",
    "\n",
    "# Download the saved model artifacts  to a local directory\n",
    "saved_model_dir = retrieved_model.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ce6d3a47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"‚ñ∏\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"‚ñæ\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBRegressor(base_score=&#x27;2.5548958E1&#x27;, booster=&#x27;gbtree&#x27;, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=None,\n",
       "             feature_types=[&#x27;float&#x27;, &#x27;float&#x27;, &#x27;float&#x27;, &#x27;float&#x27;], gamma=None,\n",
       "             grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "             multi_strategy=None, n_estimators=None, n_jobs=None,\n",
       "             num_parallel_tree=None, random_state=None, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBRegressor</label><div class=\"sk-toggleable__content\"><pre>XGBRegressor(base_score=&#x27;2.5548958E1&#x27;, booster=&#x27;gbtree&#x27;, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=None,\n",
       "             feature_types=[&#x27;float&#x27;, &#x27;float&#x27;, &#x27;float&#x27;, &#x27;float&#x27;], gamma=None,\n",
       "             grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "             multi_strategy=None, n_estimators=None, n_jobs=None,\n",
       "             num_parallel_tree=None, random_state=None, ...)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "XGBRegressor(base_score='2.5548958E1', booster='gbtree', callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=None,\n",
       "             feature_types=['float', 'float', 'float', 'float'], gamma=None,\n",
       "             grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "             multi_strategy=None, n_estimators=None, n_jobs=None,\n",
       "             num_parallel_tree=None, random_state=None, ...)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading the XGBoost regressor model and label encoder from the saved model directory\n",
    "# model_air_quality = joblib.load(saved_model_dir + \"/xgboost_regressor.pkl\")\n",
    "model_air_quality = XGBRegressor()\n",
    "\n",
    "model_air_quality.load_model(saved_model_dir + \"/model.json\")\n",
    "\n",
    "# Displaying the retrieved XGBoost regressor model\n",
    "model_air_quality"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f10c6ce0",
   "metadata": {},
   "source": [
    "## <span style='color:#ff5f27'>‚¨áÔ∏è LLM Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7ca7ea01",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-03-13 15:48:17,606 INFO: We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "495a39ae2df644ff81e5c74bd79379ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load the LLM and its corresponding tokenizer.\n",
    "model_llm, tokenizer = load_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e69d5414",
   "metadata": {},
   "source": [
    "## <span style='color:#ff5f27'>‚õìÔ∏è LangChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "218b79c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and configure a language model chain.\n",
    "llm_chain = get_llm_chain(\n",
    "    model_llm,\n",
    "    tokenizer,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "699c94a4",
   "metadata": {},
   "source": [
    "## <span style='color:#ff5f27'>üß¨ Model Inference\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6f85c08b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üóìÔ∏è Today's date: Wednesday, 2024-03-13\n",
      "üìñ \n",
      "\n",
      "Hello! How can I assist you with air quality information today?\n"
     ]
    }
   ],
   "source": [
    "QUESTION7 = \"Hi!\"\n",
    "\n",
    "response7 = generate_response(\n",
    "    QUESTION7,\n",
    "    feature_view,\n",
    "    model_llm, \n",
    "    tokenizer,\n",
    "    model_air_quality,\n",
    "    llm_chain,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "print(response7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "abb3b3fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üóìÔ∏è Today's date: Wednesday, 2024-03-13\n",
      "üìñ \n",
      "\n",
      "I am an AI-powered assistant designed to provide air quality information based on the data provided by the user. I am here to help you with any questions you may have about air quality.\n"
     ]
    }
   ],
   "source": [
    "QUESTION = \"Who are you?\"\n",
    "\n",
    "response = generate_response(\n",
    "    QUESTION,\n",
    "    feature_view,\n",
    "    model_llm,\n",
    "    tokenizer,\n",
    "    model_air_quality,\n",
    "    llm_chain,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a9c735fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished: Reading data from Hopsworks, using ArrowFlight (0.99s) \n",
      "üóìÔ∏è Today's date: Wednesday, 2024-03-13\n",
      "üìñ Air Quality Measurements:\n",
      "Date: 2024-01-10; Air Quality: 9.0\n",
      "Date: 2024-01-11; Air Quality: 8.0\n",
      "Date: 2024-01-12; Air Quality: 9.0\n",
      "Date: 2024-01-13; Air Quality: 14.0\n",
      "Date: 2024-01-14; Air Quality: 13.0\n",
      "\n",
      "The average air quality from 2024-01-10 to 2024-01-14 was 10.6. This indicates that the air quality was generally moderate during that period.\n"
     ]
    }
   ],
   "source": [
    "QUESTION1 = \"What was the average air quality from 2024-01-10 till 2024-01-14?\"\n",
    "\n",
    "response1 = generate_response(\n",
    "    QUESTION1, \n",
    "    feature_view, \n",
    "    model_llm, \n",
    "    tokenizer, \n",
    "    model_air_quality, \n",
    "    llm_chain,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "print(response1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "89013aae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished: Reading data from Hopsworks, using ArrowFlight (1.00s) \n",
      "üóìÔ∏è Today's date: Wednesday, 2024-03-13\n",
      "üìñ Air Quality Measurements:\n",
      "Date: 2024-01-10; Air Quality: 9.0\n",
      "Date: 2024-01-11; Air Quality: 8.0\n",
      "Date: 2024-01-12; Air Quality: 9.0\n",
      "Date: 2024-01-13; Air Quality: 14.0\n",
      "Date: 2024-01-14; Air Quality: 13.0\n",
      "\n",
      "The maximum air quality from 2024-01-10 to 2024-01-14 was on 2024-01-13 with an air quality level of 14.0. This indicates that the air quality on that day was considered unhealthy for sensitive groups.\n"
     ]
    }
   ],
   "source": [
    "QUESTION11 = \"When and what was the maximum air quality from 2024-01-10 till 2024-01-14?\"\n",
    "\n",
    "response11 = generate_response(\n",
    "    QUESTION11, \n",
    "    feature_view, \n",
    "    model_llm,\n",
    "    tokenizer,\n",
    "    model_air_quality,\n",
    "    llm_chain,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "print(response11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "377e0191",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished: Reading data from Hopsworks, using ArrowFlight (1.00s) \n",
      "üóìÔ∏è Today's date: Wednesday, 2024-03-13\n",
      "üìñ Air Quality Measurements:\n",
      "Date: 2024-01-10; Air Quality: 9.0\n",
      "Date: 2024-01-11; Air Quality: 8.0\n",
      "Date: 2024-01-12; Air Quality: 9.0\n",
      "Date: 2024-01-13; Air Quality: 14.0\n",
      "Date: 2024-01-14; Air Quality: 13.0\n",
      "\n",
      "The minimum air quality from 2024-01-10 to 2024-01-14 was on 2024-01-11 with an air quality level of 8.0. This indicates that the air quality on that day was considered healthy.\n"
     ]
    }
   ],
   "source": [
    "QUESTION12 = \"When and what was the minimum air quality from 2024-01-10 till 2024-01-14?\"\n",
    "\n",
    "response12 = generate_response(\n",
    "    QUESTION12, \n",
    "    feature_view, \n",
    "    model_llm, \n",
    "    tokenizer, \n",
    "    model_air_quality, \n",
    "    llm_chain,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "print(response12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a47b5fe2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished: Reading data from Hopsworks, using ArrowFlight (0.93s) \n",
      "üóìÔ∏è Today's date: Wednesday, 2024-03-13\n",
      "üìñ Air Quality Measurements:\n",
      "Date: 2024-03-12; Air Quality: 46.0\n",
      "\n",
      "The air quality yesterday, 2024-03-12, had an air quality level of 46.0. This indicates that the air quality was considered hazardous and it is not recommended to go outside.\n"
     ]
    }
   ],
   "source": [
    "QUESTION2 = \"What was the air quality yesterday?\"\n",
    "\n",
    "response2 = generate_response(\n",
    "    QUESTION2,\n",
    "    feature_view, \n",
    "    model_llm,\n",
    "    tokenizer,\n",
    "    model_air_quality,\n",
    "    llm_chain,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "print(response2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "42513372",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished: Reading data from Hopsworks, using ArrowFlight (0.99s) \n",
      "üóìÔ∏è Today's date: Wednesday, 2024-03-13\n",
      "üìñ Air Quality Measurements:\n",
      "Date: 2024-03-13; Air Quality: 51.0\n",
      "Date: 2024-03-14; Air Quality: 30.84\n",
      "Date: 2024-03-15; Air Quality: 30.84\n",
      "Date: 2024-03-16; Air Quality: 30.84\n",
      "Date: 2024-03-17; Air Quality: 30.84\n",
      "Date: 2024-03-18; Air Quality: 30.84\n",
      "\n",
      "The air quality on 2024-03-18 is expected to be at an air quality level of 30.84. This indicates that the air quality on that day was considered unhealthy for sensitive groups. It is recommended to limit outdoor activities.\n"
     ]
    }
   ],
   "source": [
    "QUESTION3 = \"What will the air quality be like in 2024-03-18?\"\n",
    "\n",
    "response3 = generate_response(\n",
    "    QUESTION3, \n",
    "    feature_view, \n",
    "    model_llm, \n",
    "    tokenizer,\n",
    "    model_air_quality,\n",
    "    llm_chain,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "print(response3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0a2f3735",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished: Reading data from Hopsworks, using ArrowFlight (1.11s) \n",
      "üóìÔ∏è Today's date: Wednesday, 2024-03-13\n",
      "üìñ Air Quality Measurements:\n",
      "Date: 2024-03-13; Air Quality: 51.0\n",
      "Date: 2024-03-14; Air Quality: 30.84\n",
      "Date: 2024-03-15; Air Quality: 30.84\n",
      "\n",
      "The air quality the day after tomorrow, 2024-03-15, is expected to be at an air quality level of 30.84. This indicates that the air quality on that day was considered unhealthy for sensitive groups. It is recommended to limit outdoor activities.\n"
     ]
    }
   ],
   "source": [
    "QUESTION4 = \"What will the air quality be like the day after tomorrow?\"\n",
    "\n",
    "response4 = generate_response(\n",
    "    QUESTION4, \n",
    "    feature_view, \n",
    "    model_llm, \n",
    "    tokenizer, \n",
    "    model_air_quality, \n",
    "    llm_chain,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "print(response4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8d5217ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished: Reading data from Hopsworks, using ArrowFlight (0.97s) \n",
      "üóìÔ∏è Today's date: Wednesday, 2024-03-13\n",
      "üìñ Air Quality Measurements:\n",
      "Date: 2024-03-13; Air Quality: 51.0\n",
      "Date: 2024-03-14; Air Quality: 30.84\n",
      "Date: 2024-03-15; Air Quality: 30.84\n",
      "Date: 2024-03-16; Air Quality: 30.84\n",
      "Date: 2024-03-17; Air Quality: 30.84\n",
      "\n",
      "The air quality on Sunday, 2024-03-17, is expected to be at an air quality level of 51.0. This indicates that the air quality on that day was considered unhealthy for sensitive groups. It is recommended to limit outdoor activities.\n"
     ]
    }
   ],
   "source": [
    "QUESTION5 = \"What will the air quality be like on Sunday?\"\n",
    "\n",
    "response5 = generate_response(\n",
    "    QUESTION5, \n",
    "    feature_view, \n",
    "    model_llm, \n",
    "    tokenizer, \n",
    "    model_air_quality, \n",
    "    llm_chain,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "print(response5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c7a57fdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished: Reading data from Hopsworks, using ArrowFlight (1.20s) \n",
      "üóìÔ∏è Today's date: Wednesday, 2024-03-13\n",
      "üìñ Air Quality Measurements:\n",
      "Date: 2024-03-13; Air Quality: 51.0\n",
      "Date: 2024-03-14; Air Quality: 30.84\n",
      "Date: 2024-03-15; Air Quality: 30.84\n",
      "Date: 2024-03-16; Air Quality: 30.84\n",
      "\n",
      "The air quality on March 16 is expected to be at an air quality level of 30.84. This indicates that the air quality on that day was considered unhealthy for sensitive groups. It is recommended to limit outdoor activities.\n"
     ]
    }
   ],
   "source": [
    "QUESTION7 = \"What will the air quality be like on March 16?\"\n",
    "\n",
    "response7 = generate_response(\n",
    "    QUESTION7, \n",
    "    feature_view,\n",
    "    model_llm,\n",
    "    tokenizer, \n",
    "    model_air_quality, \n",
    "    llm_chain,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "print(response7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9d34b219",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished: Reading data from Hopsworks, using ArrowFlight (0.89s) \n",
      "üóìÔ∏è Today's date: Wednesday, 2024-03-13\n",
      "üìñ Air Quality Measurements:\n",
      "Date: 2024-03-13; Air Quality: 51.0\n",
      "Date: 2024-03-14; Air Quality: 30.84\n",
      "Date: 2024-03-15; Air Quality: 30.84\n",
      "Date: 2024-03-16; Air Quality: 30.84\n",
      "\n",
      "The air quality on March 16 is expected to be at an air quality level of 30.84. This indicates that the air quality on that day was considered unhealthy for sensitive groups. It is recommended to limit outdoor activities.\n"
     ]
    }
   ],
   "source": [
    "QUESTION = \"Is this level safe or not?\"\n",
    "\n",
    "response = generate_response(\n",
    "    QUESTION7, \n",
    "    feature_view, \n",
    "    model_llm, \n",
    "    tokenizer,\n",
    "    model_air_quality,\n",
    "    llm_chain,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e9ead195",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üóìÔ∏è Today's date: Wednesday, 2024-03-13\n",
      "üìñ \n",
      "\n",
      "The air quality level is not dangerous, but it is not safe for everyone. It is recommended to limit outdoor activities, especially for sensitive groups such as children, the elderly, and those with respiratory issues.\n"
     ]
    }
   ],
   "source": [
    "QUESTION = \"Is this air quality level dangerous?\"\n",
    "\n",
    "response = generate_response(\n",
    "    QUESTION, \n",
    "    feature_view, \n",
    "    model_llm, \n",
    "    tokenizer,\n",
    "    model_air_quality, \n",
    "    llm_chain,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bd1a7539",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üóìÔ∏è Today's date: Wednesday, 2024-03-13\n",
      "üìñ \n",
      "\n",
      "Certainly! Air quality levels are categorized based on the Air Quality Index (AQI), which is a measure of how clean or polluted the air is. The AQI ranges from 0 to 500, with higher numbers indicating more pollution. Here are the different air quality levels and their corresponding AQI ranges:\n",
      "\n",
      "1. Good: AQI 0-50\n",
      "2. Moderate: AQI 51-100\n",
      "3. Unhealthy for Sensitive Groups: AQI 101-150\n",
      "4. Unhealthy: AQI 151-200\n",
      "5. Very Unhealthy: AQI 201-300\n",
      "6. Hazardous: AQI 301-500\n",
      "\n",
      "These categories help people understand the potential health risks associated with different air quality levels. For example, \"Good\" air quality is considered safe for everyone, while \"Unhealthy\" air quality may cause respiratory issues for sensitive groups or even the general population if the AQI is very high.\n"
     ]
    }
   ],
   "source": [
    "QUESTION = \"Can you please explain different air quality levels?\"\n",
    "\n",
    "response = generate_response(\n",
    "    QUESTION, \n",
    "    feature_view, \n",
    "    model_llm, \n",
    "    tokenizer,\n",
    "    model_air_quality, \n",
    "    llm_chain,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "486d977c",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
