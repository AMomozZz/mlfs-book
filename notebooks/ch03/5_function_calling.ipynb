{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ec5c843d",
   "metadata": {},
   "source": [
    "## <span style='color:#ff5f27'> üìù Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2c1def4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor\n",
    "import hopsworks\n",
    "from functions.llm_chain import load_model, get_llm_chain, generate_response\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f87af501",
   "metadata": {},
   "source": [
    "## <span style=\"color:#ff5f27;\"> üîÆ Connect to Hopsworks Feature Store </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3b184211",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected. Call `.close()` to terminate connection gracefully.\n",
      "\n",
      "Logged in to project, explore it here https://snurran.hops.works/p/5240\n",
      "Connected. Call `.close()` to terminate connection gracefully.\n"
     ]
    }
   ],
   "source": [
    "project = hopsworks.login()\n",
    "fs = project.get_feature_store() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ee5cae5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get_or_create the 'air_quality_fv' feature view\n",
    "feature_view = fs.get_feature_view(\n",
    "    name='air_quality_fv',\n",
    "    version=1\n",
    ")\n",
    "\n",
    "# Initialize batch scoring\n",
    "feature_view.init_batch_scoring(1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42ad4152",
   "metadata": {},
   "source": [
    "## <span style=\"color:#ff5f27;\">ü™ù Retrieve AirQuality Model from Model Registry</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5ce84f6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected. Call `.close()` to terminate connection gracefully.\n",
      "Downloading model artifact (1 dirs, 6 files)... DONE\r"
     ]
    }
   ],
   "source": [
    "# Retrieve the model registry\n",
    "mr = project.get_model_registry()\n",
    "\n",
    "# Retrieve the 'air_quality_xgboost_model' from the model registry\n",
    "retrieved_model = mr.get_model(\n",
    "    name=\"air_quality_xgboost_model\",\n",
    "    version=1,\n",
    ")\n",
    "\n",
    "# Download the saved model artifacts  to a local directory\n",
    "saved_model_dir = retrieved_model.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "af0980d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"‚ñ∏\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"‚ñæ\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBRegressor(base_score=&#x27;2.5450603E1&#x27;, booster=&#x27;gbtree&#x27;, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=None,\n",
       "             feature_types=[&#x27;float&#x27;, &#x27;float&#x27;, &#x27;float&#x27;, &#x27;float&#x27;], gamma=None,\n",
       "             grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "             multi_strategy=None, n_estimators=None, n_jobs=None,\n",
       "             num_parallel_tree=None, random_state=None, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBRegressor</label><div class=\"sk-toggleable__content\"><pre>XGBRegressor(base_score=&#x27;2.5450603E1&#x27;, booster=&#x27;gbtree&#x27;, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=None,\n",
       "             feature_types=[&#x27;float&#x27;, &#x27;float&#x27;, &#x27;float&#x27;, &#x27;float&#x27;], gamma=None,\n",
       "             grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "             multi_strategy=None, n_estimators=None, n_jobs=None,\n",
       "             num_parallel_tree=None, random_state=None, ...)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "XGBRegressor(base_score='2.5450603E1', booster='gbtree', callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=None,\n",
       "             feature_types=['float', 'float', 'float', 'float'], gamma=None,\n",
       "             grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "             multi_strategy=None, n_estimators=None, n_jobs=None,\n",
       "             num_parallel_tree=None, random_state=None, ...)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading the XGBoost regressor model and label encoder from the saved model directory\n",
    "# model_air_quality = joblib.load(saved_model_dir + \"/xgboost_regressor.pkl\")\n",
    "model_air_quality = XGBRegressor()\n",
    "\n",
    "model_air_quality.load_model(saved_model_dir + \"/model.json\")\n",
    "\n",
    "# Displaying the retrieved XGBoost regressor model\n",
    "model_air_quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "85725259",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished: Reading data from Hopsworks, using ArrowFlight (1.22s) \n",
      "         date  pm25\n",
      "0  2024-02-02  22.0\n",
      "1  2024-02-03  12.0\n",
      "2  2024-02-04  17.0\n",
      "3  2024-02-05  20.0\n"
     ]
    }
   ],
   "source": [
    "from functions.air_quality_data_retrieval import *\n",
    "date_start = \"2024-02-02\"\n",
    "date_end = \"2024-02-04\"\n",
    "res = get_historical_data_in_date_range(date_start, date_end, feature_view, model_air_quality)\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65da74f3",
   "metadata": {},
   "source": [
    "## <span style='color:#ff5f27'>‚¨áÔ∏è LLM Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "23f8ba92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "964c36517adf4840b74afb03d7ee568b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/1.60k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6a149733f904425a2a411282914b514",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.model:   0%|          | 0.00/493k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83b139f7a3e944b89c7c3892e1769fec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "added_tokens.json:   0%|          | 0.00/51.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d63114559cca4698a6236d8ebb585e11",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/101 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f7aa9e49c95417796a14e43dc0c3722",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/624 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "944613632e7a4e67872c9d4a3af221a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json:   0%|          | 0.00/25.1k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93a2c642ecde44e5a5466566ad0acf94",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3146bf6f0a14232a68b127d7150322e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00002.safetensors:   0%|          | 0.00/9.94G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ff306ba109946e7a2797e273a85a224",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00002.safetensors:   0%|          | 0.00/4.54G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-03-20 10:49:25,327 INFO: We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21cfb5b7591b49148eaecd999cf20d93",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "656d440932b0419ab35e4daa488ce1f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/120 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load the LLM and its corresponding tokenizer.\n",
    "model_llm, tokenizer = load_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67ec613b",
   "metadata": {},
   "source": [
    "## <span style='color:#ff5f27'>‚õìÔ∏è LangChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "85a33460",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and configure a language model chain.\n",
    "llm_chain = get_llm_chain(\n",
    "    model_llm,\n",
    "    tokenizer,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "239d1133",
   "metadata": {},
   "source": [
    "## <span style='color:#ff5f27'>üß¨ Model Inference\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "036a5f1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üóìÔ∏è Today's date: Wednesday, 2024-03-20\n",
      "üìñ \n",
      "\n",
      "Hello! How can I assist you with air quality information?\n"
     ]
    }
   ],
   "source": [
    "QUESTION7 = \"Hi!\"\n",
    "\n",
    "response7 = generate_response(\n",
    "    QUESTION7,\n",
    "    feature_view,\n",
    "    model_llm, \n",
    "    tokenizer,\n",
    "    model_air_quality,\n",
    "    llm_chain,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "print(response7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9466a2a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üóìÔ∏è Today's date: Wednesday, 2024-03-20\n",
      "üìñ \n",
      "\n",
      "I am an AI Air Quality Assistant, designed to provide you with information about air quality in the city provided by you. I can answer your questions about air quality and offer advice based on the data you provide.\n"
     ]
    }
   ],
   "source": [
    "QUESTION = \"Who are you?\"\n",
    "\n",
    "response = generate_response(\n",
    "    QUESTION,\n",
    "    feature_view,\n",
    "    model_llm,\n",
    "    tokenizer,\n",
    "    model_air_quality,\n",
    "    llm_chain,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "10cd1831",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished: Reading data from Hopsworks, using ArrowFlight (1.12s) \n",
      "üóìÔ∏è Today's date: Wednesday, 2024-03-20\n",
      "üìñ Air Quality Measurements:\n",
      "Date: 2024-01-10; Air Quality: 9.0\n",
      "Date: 2024-01-11; Air Quality: 8.0\n",
      "Date: 2024-01-12; Air Quality: 9.0\n",
      "Date: 2024-01-13; Air Quality: 14.0\n",
      "Date: 2024-01-14; Air Quality: 13.0\n",
      "Date: 2024-01-15; Air Quality: 8.0\n",
      "\n",
      "The average air quality from 2024-01-10 to 2024-01-14 was 10.4. This indicates that the air quality during that period was generally good, with no need to worry about going outside.\n"
     ]
    }
   ],
   "source": [
    "QUESTION1 = \"What was the average air quality from 2024-01-10 till 2024-01-14?\"\n",
    "\n",
    "response1 = generate_response(\n",
    "    QUESTION1, \n",
    "    feature_view, \n",
    "    model_llm, \n",
    "    tokenizer, \n",
    "    model_air_quality, \n",
    "    llm_chain,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "print(response1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a022bf44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished: Reading data from Hopsworks, using ArrowFlight (0.91s) \n",
      "üóìÔ∏è Today's date: Wednesday, 2024-03-20\n",
      "üìñ Air Quality Measurements:\n",
      "Date: 2024-03-12; Air Quality: 46.0\n",
      "Date: 2024-03-13; Air Quality: 51.0\n",
      "Date: 2024-03-14; Air Quality: 41.0\n",
      "Date: 2024-03-15; Air Quality: 54.0\n",
      "Date: 2024-03-16; Air Quality: 45.0\n",
      "Date: 2024-03-19; Air Quality: 17.0\n",
      "\n",
      "Last week, on 2024-03-12, the air quality was 46.0, indicating that the air quality was unhealthy for sensitive groups. On 2024-03-13, the air quality was 51.0, which is also unhealthy for sensitive groups. On 2024-03-14, the air quality improved to 41.0, which was considered unhealthy. On 2024-03-15, the air quality was 54.0, which is unhealthy for sensitive groups. On 2024-03-16, the air quality was 45.0, which is also unhealthy for sensitive groups. On 2024-03-19, the air quality improved to 17.0, which is considered safe for everyone.\n"
     ]
    }
   ],
   "source": [
    "QUESTION11 = \"When and what was the air quality like last week?\"\n",
    "\n",
    "response11 = generate_response(\n",
    "    QUESTION11, \n",
    "    feature_view, \n",
    "    model_llm,\n",
    "    tokenizer,\n",
    "    model_air_quality,\n",
    "    llm_chain,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "print(response11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4bf5a093",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished: Reading data from Hopsworks, using ArrowFlight (0.93s) \n",
      "üóìÔ∏è Today's date: Wednesday, 2024-03-20\n",
      "üìñ Air Quality Measurements:\n",
      "Date: 2024-01-10; Air Quality: 9.0\n",
      "Date: 2024-01-11; Air Quality: 8.0\n",
      "Date: 2024-01-12; Air Quality: 9.0\n",
      "Date: 2024-01-13; Air Quality: 14.0\n",
      "Date: 2024-01-14; Air Quality: 13.0\n",
      "Date: 2024-01-15; Air Quality: 8.0\n",
      "\n",
      "The minimum air quality from 2024-01-10 to 2024-01-14 was on 2024-01-15, with an air quality of 8.0. This indicates that the air quality during that period was generally good, with no need to worry about going outside.\n"
     ]
    }
   ],
   "source": [
    "QUESTION12 = \"When and what was the minimum air quality from 2024-01-10 till 2024-01-14?\"\n",
    "\n",
    "response12 = generate_response(\n",
    "    QUESTION12, \n",
    "    feature_view, \n",
    "    model_llm, \n",
    "    tokenizer, \n",
    "    model_air_quality, \n",
    "    llm_chain,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "print(response12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "96f61c8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished: Reading data from Hopsworks, using ArrowFlight (1.02s) \n",
      "üóìÔ∏è Today's date: Wednesday, 2024-03-20\n",
      "üìñ Air Quality Measurements:\n",
      "Date: 2024-03-13; Air Quality: 51.0\n",
      "Date: 2024-03-14; Air Quality: 41.0\n",
      "Date: 2024-03-15; Air Quality: 54.0\n",
      "Date: 2024-03-16; Air Quality: 45.0\n",
      "Date: 2024-03-19; Air Quality: 17.0\n",
      "Date: 2024-03-20; Air Quality: 17.0\n",
      "\n",
      "Last week, the air quality was generally good. On 2024-03-19 and 2024-03-20, the air quality was 17.0, indicating that the air quality was safe for everyone. On 2024-03-15, the air quality was 54.0, which is unhealthy for sensitive groups. On 2024-03-16, the air quality was 45.0, which is also unhealthy for sensitive groups. On 2024-03-13, the air quality was 51.0, which is unhealthy for sensitive groups. On 2024-03-14, the air quality was 41.0, which was considered unhealthy.\n"
     ]
    }
   ],
   "source": [
    "QUESTION2a = \"What was the air quality like last week?\"\n",
    "\n",
    "response2 = generate_response(\n",
    "    QUESTION2a,\n",
    "    feature_view, \n",
    "    model_llm,\n",
    "    tokenizer,\n",
    "    model_air_quality,\n",
    "    llm_chain,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "print(response2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "075b424c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished: Reading data from Hopsworks, using ArrowFlight (0.97s) \n",
      "üóìÔ∏è Today's date: Wednesday, 2024-03-20\n",
      "üìñ Air Quality Measurements:\n",
      "Date: 2024-03-19; Air Quality: 17.0\n",
      "\n",
      "Yesterday, the air quality was safe for everyone. The air quality measurement was 17.0, indicating that the air quality was safe for everyone.\n"
     ]
    }
   ],
   "source": [
    "QUESTION2 = \"What was the air quality like yesterday?\"\n",
    "\n",
    "response2 = generate_response(\n",
    "    QUESTION2,\n",
    "    feature_view, \n",
    "    model_llm,\n",
    "    tokenizer,\n",
    "    model_air_quality,\n",
    "    llm_chain,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "print(response2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "565c0be6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connection closed.\n",
      "Connected. Call `.close()` to terminate connection gracefully.\n",
      "\n",
      "Logged in to project, explore it here https://snurran.hops.works/p/5240\n",
      "Connected. Call `.close()` to terminate connection gracefully.\n",
      "Finished: Reading data from Hopsworks, using ArrowFlight (0.53s) \n",
      "üóìÔ∏è Today's date: Wednesday, 2024-03-20\n",
      "üìñ Air Quality Measurements:\n",
      "\n",
      "\n",
      "On 2024-03-20, the air quality was 17.0, indicating that the air quality was safe for everyone. You can go outside and enjoy the day without any concerns about the air quality.\n"
     ]
    }
   ],
   "source": [
    "QUESTION3 = \"What will the air quality be like on 2024-03-20?\"\n",
    "\n",
    "response3 = generate_response(\n",
    "    QUESTION3, \n",
    "    feature_view, \n",
    "    model_llm, \n",
    "    tokenizer,\n",
    "    model_air_quality,\n",
    "    llm_chain,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "print(response3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f404beb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connection closed.\n",
      "Connected. Call `.close()` to terminate connection gracefully.\n",
      "\n",
      "Logged in to project, explore it here https://snurran.hops.works/p/5240\n",
      "Connected. Call `.close()` to terminate connection gracefully.\n",
      "Finished: Reading data from Hopsworks, using ArrowFlight (0.46s) \n",
      "üóìÔ∏è Today's date: Wednesday, 2024-03-20\n",
      "üìñ Air Quality Measurements:\n",
      "\n",
      "\n",
      "I'm sorry, but I can't predict the air quality for the day after tomorrow. The air quality can change depending on various factors such as weather, pollution sources, and other environmental conditions.\n"
     ]
    }
   ],
   "source": [
    "QUESTION4 = \"What will the air quality be like the day after tomorrow?\"\n",
    "\n",
    "response4 = generate_response(\n",
    "    QUESTION4, \n",
    "    feature_view, \n",
    "    model_llm, \n",
    "    tokenizer, \n",
    "    model_air_quality, \n",
    "    llm_chain,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "print(response4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b48c5623",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connection closed.\n",
      "Connected. Call `.close()` to terminate connection gracefully.\n",
      "\n",
      "Logged in to project, explore it here https://snurran.hops.works/p/5240\n",
      "Connected. Call `.close()` to terminate connection gracefully.\n",
      "Finished: Reading data from Hopsworks, using ArrowFlight (0.56s) \n",
      "üóìÔ∏è Today's date: Wednesday, 2024-03-20\n",
      "üìñ Air Quality Measurements:\n",
      "\n",
      "\n",
      "I'm sorry, but I can't predict the air quality for this Sunday. The air quality can change depending on various factors such as weather, pollution sources, and other environmental conditions.\n"
     ]
    }
   ],
   "source": [
    "QUESTION5 = \"What will the air quality be like this Sunday?\"\n",
    "\n",
    "response5 = generate_response(\n",
    "    QUESTION5, \n",
    "    feature_view, \n",
    "    model_llm, \n",
    "    tokenizer, \n",
    "    model_air_quality, \n",
    "    llm_chain,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "print(response5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b38ec00e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connection closed.\n",
      "Connected. Call `.close()` to terminate connection gracefully.\n",
      "\n",
      "Logged in to project, explore it here https://snurran.hops.works/p/5240\n",
      "Connected. Call `.close()` to terminate connection gracefully.\n",
      "Finished: Reading data from Hopsworks, using ArrowFlight (0.62s) \n",
      "üóìÔ∏è Today's date: Wednesday, 2024-03-20\n",
      "üìñ Air Quality Measurements:\n",
      "Date: 2024-03-24 00:00:00; Air Quality: 41.25\n",
      "Date: 2024-03-25 00:00:00; Air Quality: 58.89\n",
      "Date: 2024-03-26 00:00:00; Air Quality: 47.22\n",
      "Date: 2024-03-27 00:00:00; Air Quality: 39.18\n",
      "Date: 2024-03-28 00:00:00; Air Quality: 39.91\n",
      "\n",
      "I'm sorry, but I can't predict the air quality for the rest of the week. The air quality can change depending on various factors such as weather, pollution sources, and other environmental conditions.\n"
     ]
    }
   ],
   "source": [
    "QUESTION7 = \"What will the air quality be like for the rest of the week?\"\n",
    "\n",
    "response7 = generate_response(\n",
    "    QUESTION7, \n",
    "    feature_view,\n",
    "    model_llm,\n",
    "    tokenizer, \n",
    "    model_air_quality, \n",
    "    llm_chain,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "print(response7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "87bfe6cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connection closed.\n",
      "Connected. Call `.close()` to terminate connection gracefully.\n",
      "\n",
      "Logged in to project, explore it here https://snurran.hops.works/p/5240\n",
      "Connected. Call `.close()` to terminate connection gracefully.\n",
      "Finished: Reading data from Hopsworks, using ArrowFlight (0.45s) \n",
      "üóìÔ∏è Today's date: Wednesday, 2024-03-20\n",
      "üìñ Air Quality Measurements:\n",
      "Date: 2024-03-24 00:00:00; Air Quality: 41.25\n",
      "Date: 2024-03-25 00:00:00; Air Quality: 58.89\n",
      "Date: 2024-03-26 00:00:00; Air Quality: 47.22\n",
      "Date: 2024-03-27 00:00:00; Air Quality: 39.18\n",
      "Date: 2024-03-28 00:00:00; Air Quality: 39.91\n",
      "\n",
      "I'm sorry, but I can't predict the air quality for the rest of the week. The air quality can change depending on various factors such as weather, pollution sources, and other environmental conditions.\n"
     ]
    }
   ],
   "source": [
    "QUESTION = \"Will the air quality be safe or not for the next week?\"\n",
    "\n",
    "response = generate_response(\n",
    "    QUESTION7, \n",
    "    feature_view, \n",
    "    model_llm, \n",
    "    tokenizer,\n",
    "    model_air_quality,\n",
    "    llm_chain,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "80a256ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connection closed.\n",
      "Connected. Call `.close()` to terminate connection gracefully.\n",
      "\n",
      "Logged in to project, explore it here https://snurran.hops.works/p/5240\n",
      "Connected. Call `.close()` to terminate connection gracefully.\n",
      "Finished: Reading data from Hopsworks, using ArrowFlight (0.43s) \n",
      "üóìÔ∏è Today's date: Wednesday, 2024-03-20\n",
      "üìñ Air Quality Measurements:\n",
      "\n",
      "\n",
      "I'm sorry, but I can't predict the air quality for tomorrow. The air quality can change depending on various factors such as weather, pollution sources, and other environmental conditions.\n"
     ]
    }
   ],
   "source": [
    "QUESTION = \"Is tomorrow's air quality level dangerous?\"\n",
    "\n",
    "response = generate_response(\n",
    "    QUESTION, \n",
    "    feature_view, \n",
    "    model_llm, \n",
    "    tokenizer,\n",
    "    model_air_quality, \n",
    "    llm_chain,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "abef7d17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üóìÔ∏è Today's date: Wednesday, 2024-03-20\n",
      "üìñ \n",
      "\n",
      "Of course! Air quality levels are typically measured using an index, such as the Air Quality Index (AQI), which ranges from 0 to 500. Here's a brief explanation of the different air quality levels:\n",
      "\n",
      "0-50: Good air quality, which means the air is clean and poses little or no risk.\n",
      "\n",
      "51-100: Moderate air quality, which means the air is generally clean, but there may be some health concerns for sensitive groups, such as the elderly or those with respiratory issues.\n",
      "\n",
      "101-150: Unhealthy for sensitive groups, which means that although the air quality is still considered moderate, it may pose health risks for certain groups, such as children, the elderly, and those with respiratory issues.\n",
      "\n",
      "151-200: Unhealthy air quality, which means that the air quality is not safe for the general public, particularly for those with respiratory issues or heart disease.\n",
      "\n",
      "201-300: Very unhealthy air quality, which means that the air quality is hazardous and can cause serious health effects for everyone, including healthy individuals.\n",
      "\n",
      "301-500: Hazardous air quality, which means that the air quality is extremely dangerous and can cause severe health effects, such as death, in a short period of time.\n",
      "\n",
      "Please let me know if you have any further questions or if you need information on the air quality for a specific date.\n"
     ]
    }
   ],
   "source": [
    "QUESTION = \"Can you please explain different air quality levels?\"\n",
    "\n",
    "response = generate_response(\n",
    "    QUESTION, \n",
    "    feature_view, \n",
    "    model_llm, \n",
    "    tokenizer,\n",
    "    model_air_quality, \n",
    "    llm_chain,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "28597822",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-03-20 10:51:51,163 INFO: generated new fontManager\n",
      "2024-03-20 10:51:51,477 INFO: HTTP Request: GET https://api.gradio.app/gradio-messaging/en \"HTTP/1.1 200 OK\"\n"
     ]
    }
   ],
   "source": [
    "import gradio as gr\n",
    "from transformers import pipeline\n",
    "import numpy as np\n",
    "import hopsworks\n",
    "from xgboost import XGBRegressor\n",
    "from functions.llm_chain import load_model, get_llm_chain, generate_response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3e7d1d9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7f241282e9f4e0fb9d45f13e1966c01",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.94k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0585b9c33fbf459181893be988221eeb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/290M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15e18c6b3adc457f9882efbac94935e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/1.53k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1fe85b0c39e84ce8a6123a5275ac467d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/805 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69c11734f6ed4311bef9a3196433c0ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/798k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e7409ef9fa648a59a88c07737aebbf8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/2.41M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b56591f7a7341c9bb35baa34947ef6b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb5c228ee04f4975865dbd012d2bcb03",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "normalizer.json:   0%|          | 0.00/52.7k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "336bc6cfbf034763953a2bc865d975b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "added_tokens.json:   0%|          | 0.00/34.6k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3eaf111c66464482a548f7f54f54b56c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/1.83k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d62ce2910c440699844c8e25161d131",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "preprocessor_config.json:   0%|          | 0.00/185k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7860\n",
      "2024-03-20 10:52:00,100 INFO: HTTP Request: GET http://127.0.0.1:7860/startup-events \"HTTP/1.1 200 OK\"\n",
      "2024-03-20 10:52:00,174 INFO: HTTP Request: GET https://checkip.amazonaws.com/ \"HTTP/1.1 200 \"\n",
      "2024-03-20 10:52:00,689 INFO: HTTP Request: GET https://api.gradio.app/pkg-version \"HTTP/1.1 200 OK\"\n",
      "2024-03-20 10:52:00,944 INFO: HTTP Request: POST https://api.gradio.app/gradio-initiated-analytics/ \"HTTP/1.1 200 OK\"\n",
      "2024-03-20 10:52:02,176 INFO: HTTP Request: HEAD http://127.0.0.1:7860/ \"HTTP/1.1 200 OK\"\n",
      "2024-03-20 10:52:11,599 INFO: HTTP Request: GET https://api.gradio.app/v2/tunnel-request \"HTTP/1.1 200 OK\"\n",
      "2024-03-20 10:52:11,732 INFO: HTTP Request: GET https://cdn-media.huggingface.co/frpc-gradio-0.2/frpc_linux_amd64 \"HTTP/1.1 200 OK\"\n",
      "Running on public URL: https://b28c6fa14cfcdba855.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n",
      "2024-03-20 10:52:13,272 INFO: HTTP Request: HEAD https://b28c6fa14cfcdba855.gradio.live \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://b28c6fa14cfcdba855.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-03-20 10:52:13,992 INFO: HTTP Request: POST https://api.gradio.app/gradio-launched-telemetry/ \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/srv/hops/anaconda/envs/theenv/lib/python3.10/site-packages/gradio/queueing.py\", line 501, in call_prediction\n",
      "    output = await route_utils.call_process_api(\n",
      "  File \"/srv/hops/anaconda/envs/theenv/lib/python3.10/site-packages/gradio/route_utils.py\", line 253, in call_process_api\n",
      "    output = await app.get_blocks().process_api(\n",
      "  File \"/srv/hops/anaconda/envs/theenv/lib/python3.10/site-packages/gradio/blocks.py\", line 1695, in process_api\n",
      "    result = await self.call_function(\n",
      "  File \"/srv/hops/anaconda/envs/theenv/lib/python3.10/site-packages/gradio/blocks.py\", line 1235, in call_function\n",
      "    prediction = await anyio.to_thread.run_sync(\n",
      "  File \"/srv/hops/anaconda/envs/theenv/lib/python3.10/site-packages/anyio/to_thread.py\", line 56, in run_sync\n",
      "    return await get_async_backend().run_sync_in_worker_thread(\n",
      "  File \"/srv/hops/anaconda/envs/theenv/lib/python3.10/site-packages/anyio/_backends/_asyncio.py\", line 2134, in run_sync_in_worker_thread\n",
      "    return await future\n",
      "  File \"/srv/hops/anaconda/envs/theenv/lib/python3.10/asyncio/futures.py\", line 285, in __await__\n",
      "    yield self  # This tells Task to wait for completion.\n",
      "  File \"/srv/hops/anaconda/envs/theenv/lib/python3.10/asyncio/tasks.py\", line 304, in __wakeup\n",
      "    future.result()\n",
      "  File \"/srv/hops/anaconda/envs/theenv/lib/python3.10/asyncio/futures.py\", line 201, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "  File \"/srv/hops/anaconda/envs/theenv/lib/python3.10/site-packages/anyio/_backends/_asyncio.py\", line 851, in run\n",
      "    result = context.run(func, *args)\n",
      "  File \"/srv/hops/anaconda/envs/theenv/lib/python3.10/site-packages/gradio/utils.py\", line 692, in wrapper\n",
      "    response = f(*args, **kwargs)\n",
      "  File \"<ipython-input-24-76c493203d89>\", line 31, in handle_input\n",
      "    return generate_query_response(user_query)\n",
      "  File \"<ipython-input-24-76c493203d89>\", line 13, in generate_query_response\n",
      "    response = generate_response(\n",
      "  File \"/home/yarnapp/hopsfs/Jupyter/mlfs-book/notebooks/ch03/functions/llm_chain.py\", line 175, in generate_response\n",
      "    context = get_context_data(\n",
      "  File \"/home/yarnapp/hopsfs/Jupyter/mlfs-book/notebooks/ch03/functions/context_engineering.py\", line 184, in get_context_data\n",
      "    data = invoke_function(functions[0], feature_view, model_air_quality)\n",
      "  File \"/home/yarnapp/hopsfs/Jupyter/mlfs-book/notebooks/ch03/functions/context_engineering.py\", line 143, in invoke_function\n",
      "    function_output = getattr(sys.modules[__name__], function_name)(\n",
      "  File \"/home/yarnapp/hopsfs/Jupyter/mlfs-book/notebooks/ch03/functions/air_quality_data_retrieval.py\", line 22, in get_historical_data_for_date\n",
      "    features_df, labels_df = feature_view.training_data(\n",
      "  File \"/srv/hops/anaconda/envs/theenv/lib/python3.10/site-packages/hsfs/usage.py\", line 198, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/srv/hops/anaconda/envs/theenv/lib/python3.10/site-packages/hsfs/feature_view.py\", line 2033, in training_data\n",
      "    td, df = self._feature_view_engine.get_training_data(\n",
      "  File \"/srv/hops/anaconda/envs/theenv/lib/python3.10/site-packages/hsfs/core/feature_view_engine.py\", line 298, in get_training_data\n",
      "    td_updated = self._create_training_data_metadata(\n",
      "  File \"/srv/hops/anaconda/envs/theenv/lib/python3.10/site-packages/hsfs/core/feature_view_engine.py\", line 667, in _create_training_data_metadata\n",
      "    td = self._feature_view_api.create_training_dataset(\n",
      "  File \"/srv/hops/anaconda/envs/theenv/lib/python3.10/site-packages/hsfs/core/feature_view_api.py\", line 190, in create_training_dataset\n",
      "    self._client._send_request(\n",
      "  File \"/srv/hops/anaconda/envs/theenv/lib/python3.10/site-packages/hsfs/decorators.py\", line 34, in if_connected\n",
      "    raise NoHopsworksConnectionError\n",
      "hsfs.decorators.NoHopsworksConnectionError: Connection is not active. Needs to be connected for feature store operations.\n",
      "Traceback (most recent call last):\n",
      "  File \"/srv/hops/anaconda/envs/theenv/lib/python3.10/site-packages/gradio/queueing.py\", line 501, in call_prediction\n",
      "    output = await route_utils.call_process_api(\n",
      "  File \"/srv/hops/anaconda/envs/theenv/lib/python3.10/site-packages/gradio/route_utils.py\", line 253, in call_process_api\n",
      "    output = await app.get_blocks().process_api(\n",
      "  File \"/srv/hops/anaconda/envs/theenv/lib/python3.10/site-packages/gradio/blocks.py\", line 1695, in process_api\n",
      "    result = await self.call_function(\n",
      "  File \"/srv/hops/anaconda/envs/theenv/lib/python3.10/site-packages/gradio/blocks.py\", line 1235, in call_function\n",
      "    prediction = await anyio.to_thread.run_sync(\n",
      "  File \"/srv/hops/anaconda/envs/theenv/lib/python3.10/site-packages/anyio/to_thread.py\", line 56, in run_sync\n",
      "    return await get_async_backend().run_sync_in_worker_thread(\n",
      "  File \"/srv/hops/anaconda/envs/theenv/lib/python3.10/site-packages/anyio/_backends/_asyncio.py\", line 2134, in run_sync_in_worker_thread\n",
      "    return await future\n",
      "  File \"/srv/hops/anaconda/envs/theenv/lib/python3.10/asyncio/futures.py\", line 285, in __await__\n",
      "    yield self  # This tells Task to wait for completion.\n",
      "  File \"/srv/hops/anaconda/envs/theenv/lib/python3.10/asyncio/tasks.py\", line 304, in __wakeup\n",
      "    future.result()\n",
      "  File \"/srv/hops/anaconda/envs/theenv/lib/python3.10/asyncio/futures.py\", line 201, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "  File \"/srv/hops/anaconda/envs/theenv/lib/python3.10/site-packages/anyio/_backends/_asyncio.py\", line 851, in run\n",
      "    result = context.run(func, *args)\n",
      "  File \"/srv/hops/anaconda/envs/theenv/lib/python3.10/site-packages/gradio/utils.py\", line 692, in wrapper\n",
      "    response = f(*args, **kwargs)\n",
      "  File \"<ipython-input-24-76c493203d89>\", line 31, in handle_input\n",
      "    return generate_query_response(user_query)\n",
      "  File \"<ipython-input-24-76c493203d89>\", line 13, in generate_query_response\n",
      "    response = generate_response(\n",
      "  File \"/home/yarnapp/hopsfs/Jupyter/mlfs-book/notebooks/ch03/functions/llm_chain.py\", line 175, in generate_response\n",
      "    context = get_context_data(\n",
      "  File \"/home/yarnapp/hopsfs/Jupyter/mlfs-book/notebooks/ch03/functions/context_engineering.py\", line 184, in get_context_data\n",
      "    data = invoke_function(functions[0], feature_view, model_air_quality)\n",
      "  File \"/home/yarnapp/hopsfs/Jupyter/mlfs-book/notebooks/ch03/functions/context_engineering.py\", line 143, in invoke_function\n",
      "    function_output = getattr(sys.modules[__name__], function_name)(\n",
      "  File \"/home/yarnapp/hopsfs/Jupyter/mlfs-book/notebooks/ch03/functions/air_quality_data_retrieval.py\", line 22, in get_historical_data_for_date\n",
      "    features_df, labels_df = feature_view.training_data(\n",
      "  File \"/srv/hops/anaconda/envs/theenv/lib/python3.10/site-packages/hsfs/usage.py\", line 198, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/srv/hops/anaconda/envs/theenv/lib/python3.10/site-packages/hsfs/feature_view.py\", line 2033, in training_data\n",
      "    td, df = self._feature_view_engine.get_training_data(\n",
      "  File \"/srv/hops/anaconda/envs/theenv/lib/python3.10/site-packages/hsfs/core/feature_view_engine.py\", line 298, in get_training_data\n",
      "    td_updated = self._create_training_data_metadata(\n",
      "  File \"/srv/hops/anaconda/envs/theenv/lib/python3.10/site-packages/hsfs/core/feature_view_engine.py\", line 667, in _create_training_data_metadata\n",
      "    td = self._feature_view_api.create_training_dataset(\n",
      "  File \"/srv/hops/anaconda/envs/theenv/lib/python3.10/site-packages/hsfs/core/feature_view_api.py\", line 190, in create_training_dataset\n",
      "    self._client._send_request(\n",
      "  File \"/srv/hops/anaconda/envs/theenv/lib/python3.10/site-packages/hsfs/decorators.py\", line 34, in if_connected\n",
      "    raise NoHopsworksConnectionError\n",
      "hsfs.decorators.NoHopsworksConnectionError: Connection is not active. Needs to be connected for feature store operations.\n"
     ]
    }
   ],
   "source": [
    "# Initialize the ASR pipeline\n",
    "transcriber = pipeline(\"automatic-speech-recognition\", model=\"openai/whisper-base.en\")\n",
    "\n",
    "def transcribe(audio):\n",
    "    sr, y = audio\n",
    "    y = y.astype(np.float32)\n",
    "    if y.ndim > 1 and y.shape[1] > 1:\n",
    "        y = np.mean(y, axis=1)\n",
    "    y /= np.max(np.abs(y))\n",
    "    return transcriber({\"sampling_rate\": sr, \"raw\": y})[\"text\"]\n",
    "\n",
    "def generate_query_response(user_query):\n",
    "    response = generate_response(\n",
    "        user_query,\n",
    "        feature_view,\n",
    "        model_llm,\n",
    "        tokenizer,\n",
    "        model_air_quality,\n",
    "        llm_chain,\n",
    "        verbose=False,\n",
    "    )\n",
    "    return response\n",
    "\n",
    "def handle_input(text_input=None, audio_input=None):\n",
    "    if audio_input is not None:\n",
    "        user_query = transcribe(audio_input)\n",
    "    else:\n",
    "        user_query = text_input\n",
    "    \n",
    "    if user_query:\n",
    "        return generate_query_response(user_query)\n",
    "    else:\n",
    "        return \"Please provide input either via text or voice.\"\n",
    "\n",
    "iface = gr.Interface(\n",
    "    fn=handle_input,\n",
    "    inputs=[gr.Textbox(placeholder=\"Type here or use voice input...\"), gr.Audio()],\n",
    "    outputs=\"text\",\n",
    "    title=\"üå§Ô∏è AirQuality AI Assistant üí¨\",\n",
    "    description=\"Ask your questions about air quality or use your voice to interact.\"\n",
    ")\n",
    "\n",
    "iface.launch(share=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ab87d6d",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
