{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "19169e3b",
   "metadata": {},
   "source": [
    "## <span style='color:#ff5f27'> üìù Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "29f1edf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor\n",
    "import hopsworks\n",
    "from functions.llm_chain import load_model, get_llm_chain, generate_response\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f36d5450",
   "metadata": {},
   "source": [
    "## <span style=\"color:#ff5f27;\"> üîÆ Connect to Hopsworks Feature Store </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6c303189",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected. Call `.close()` to terminate connection gracefully.\n",
      "\n",
      "Logged in to project, explore it here https://snurran.hops.works/p/5240\n",
      "Connected. Call `.close()` to terminate connection gracefully.\n"
     ]
    }
   ],
   "source": [
    "project = hopsworks.login()\n",
    "fs = project.get_feature_store() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "30812e9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get_or_create the 'air_quality_fv' feature view\n",
    "feature_view = fs.get_feature_view(\n",
    "    name='air_quality_fv',\n",
    "    version=1\n",
    ")\n",
    "\n",
    "# Initialize batch scoring\n",
    "feature_view.init_batch_scoring(1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ebc7f63",
   "metadata": {},
   "source": [
    "## <span style=\"color:#ff5f27;\">ü™ù Retrieve AirQuality Model from Model Registry</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8ee6a07f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected. Call `.close()` to terminate connection gracefully.\n",
      "Downloading model artifact (1 dirs, 6 files)... DONE\r"
     ]
    }
   ],
   "source": [
    "# Retrieve the model registry\n",
    "mr = project.get_model_registry()\n",
    "\n",
    "# Retrieve the 'air_quality_xgboost_model' from the model registry\n",
    "retrieved_model = mr.get_model(\n",
    "    name=\"air_quality_xgboost_model\",\n",
    "    version=1,\n",
    ")\n",
    "\n",
    "# Download the saved model artifacts  to a local directory\n",
    "saved_model_dir = retrieved_model.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "763f5365",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"‚ñ∏\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"‚ñæ\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBRegressor(base_score=&#x27;2.5450603E1&#x27;, booster=&#x27;gbtree&#x27;, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=None,\n",
       "             feature_types=[&#x27;float&#x27;, &#x27;float&#x27;, &#x27;float&#x27;, &#x27;float&#x27;], gamma=None,\n",
       "             grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "             multi_strategy=None, n_estimators=None, n_jobs=None,\n",
       "             num_parallel_tree=None, random_state=None, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBRegressor</label><div class=\"sk-toggleable__content\"><pre>XGBRegressor(base_score=&#x27;2.5450603E1&#x27;, booster=&#x27;gbtree&#x27;, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=None,\n",
       "             feature_types=[&#x27;float&#x27;, &#x27;float&#x27;, &#x27;float&#x27;, &#x27;float&#x27;], gamma=None,\n",
       "             grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "             multi_strategy=None, n_estimators=None, n_jobs=None,\n",
       "             num_parallel_tree=None, random_state=None, ...)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "XGBRegressor(base_score='2.5450603E1', booster='gbtree', callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=None,\n",
       "             feature_types=['float', 'float', 'float', 'float'], gamma=None,\n",
       "             grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "             multi_strategy=None, n_estimators=None, n_jobs=None,\n",
       "             num_parallel_tree=None, random_state=None, ...)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading the XGBoost regressor model and label encoder from the saved model directory\n",
    "# model_air_quality = joblib.load(saved_model_dir + \"/xgboost_regressor.pkl\")\n",
    "model_air_quality = XGBRegressor()\n",
    "\n",
    "model_air_quality.load_model(saved_model_dir + \"/model.json\")\n",
    "\n",
    "# Displaying the retrieved XGBoost regressor model\n",
    "model_air_quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2363a466",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished: Reading data from Hopsworks, using ArrowFlight (0.85s) \n",
      "         date  pm25\n",
      "0  2024-02-02  22.0\n",
      "1  2024-02-03  12.0\n",
      "2  2024-02-04  17.0\n",
      "3  2024-02-05  20.0\n"
     ]
    }
   ],
   "source": [
    "from functions.air_quality_data_retrieval import *\n",
    "date_start = \"2024-02-02\"\n",
    "date_end = \"2024-02-04\"\n",
    "res = get_historical_data_in_date_range(date_start, date_end, feature_view, model_air_quality)\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a157b46f",
   "metadata": {},
   "source": [
    "## <span style='color:#ff5f27'>‚¨áÔ∏è LLM Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1abe3226",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You set `add_prefix_space`. The tokenizer needs to be converted from the slow tokenizers\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from disk\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`low_cpu_mem_usage` was None, now set to True since model is quantized.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The code execution took 11.15595006942749 seconds.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "# Load the LLM and its corresponding tokenizer.\n",
    "model_llm, tokenizer = load_model()\n",
    "\n",
    "duration = time.time() - start_time\n",
    "print(f\"The code execution took {duration} seconds.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1be4d204",
   "metadata": {},
   "source": [
    "## <span style='color:#ff5f27'>‚õìÔ∏è LangChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e42efa28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The code execution took 0.39171886444091797 seconds.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "\n",
    "# Create and configure a language model chain.\n",
    "llm_chain = get_llm_chain(\n",
    "    model_llm,\n",
    "    tokenizer,\n",
    ")\n",
    "\n",
    "duration = time.time() - start_time\n",
    "print(f\"The code execution took {duration} seconds.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60fb0218",
   "metadata": {},
   "source": [
    "## <span style='color:#ff5f27'>üß¨ Model Inference\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4683e78a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üóìÔ∏è Today's date: Saturday, 2024-03-23\n",
      "üìñ \n",
      "\n",
      "Hello! How can I assist you with air quality information today?\n"
     ]
    }
   ],
   "source": [
    "QUESTION7 = \"Hi!\"\n",
    "\n",
    "response7 = generate_response(\n",
    "    QUESTION7,\n",
    "    feature_view,\n",
    "    model_llm, \n",
    "    tokenizer,\n",
    "    model_air_quality,\n",
    "    llm_chain,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "print(response7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0957bb05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üóìÔ∏è Today's date: Saturday, 2024-03-23\n",
      "üìñ \n",
      "\n",
      "I am an AI assistant designed to provide air quality information based on the data provided by the user. I can help you with air quality information for a specific date or location.\n"
     ]
    }
   ],
   "source": [
    "QUESTION = \"Who are you?\"\n",
    "\n",
    "response = generate_response(\n",
    "    QUESTION,\n",
    "    feature_view,\n",
    "    model_llm,\n",
    "    tokenizer,\n",
    "    model_air_quality,\n",
    "    llm_chain,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "afcccf7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished: Reading data from Hopsworks, using ArrowFlight (0.81s) \n",
      "üóìÔ∏è Today's date: Saturday, 2024-03-23\n",
      "üìñ Air Quality Measurements:\n",
      "Date: 2024-01-10; Air Quality: 9.0\n",
      "Date: 2024-01-11; Air Quality: 8.0\n",
      "Date: 2024-01-12; Air Quality: 9.0\n",
      "Date: 2024-01-13; Air Quality: 14.0\n",
      "Date: 2024-01-14; Air Quality: 13.0\n",
      "Date: 2024-01-15; Air Quality: 8.0\n",
      "\n",
      "The average air quality from 2024-01-10 to 2024-01-14 was 10.2. This indicates that the air quality during that period was generally moderate, and it may have been safe for most people to go outside. However, it's always a good idea to check local air quality advisories and take precautions if you have respiratory sensitivities.\n"
     ]
    }
   ],
   "source": [
    "QUESTION1 = \"What was the average air quality from 2024-01-10 till 2024-01-14?\"\n",
    "\n",
    "response1 = generate_response(\n",
    "    QUESTION1, \n",
    "    feature_view, \n",
    "    model_llm, \n",
    "    tokenizer, \n",
    "    model_air_quality, \n",
    "    llm_chain,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "print(response1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3599748c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished: Reading data from Hopsworks, using ArrowFlight (0.88s) \n",
      "üóìÔ∏è Today's date: Saturday, 2024-03-23\n",
      "üìñ Air Quality Measurements:\n",
      "Date: 2024-03-19; Air Quality: 17.0\n",
      "Date: 2024-03-20; Air Quality: 17.0\n",
      "Date: 2024-03-21; Air Quality: 41.0\n",
      "Date: 2024-03-22; Air Quality: 14.0\n",
      "Date: 2024-03-23; Air Quality: 20.0\n",
      "\n",
      "Last week, the air quality was as follows:\n",
      "\n",
      "- On 2024-03-19, the air quality was 17.0, which indicates that the air quality was generally moderate and it may have been safe for most people to go outside.\n",
      "- On 2024-03-20, the air quality was 17.0, which is the same as the day before. This also indicates moderate air quality and it may have been safe for most people to go outside.\n",
      "- On 2024-03-21, the air quality was 41.0, which indicates that the air quality was very poor and it may have been best to limit outdoor activities, especially if you have respiratory sensitivities.\n",
      "- On 2024-03-22, the air quality was 14.0, which indicates that the air quality was unhealthy for sensitive groups, such as children, the elderly, and those with respiratory conditions. It may have been safe for most people to go outside, but it's best to check local air quality advisories for updates.\n",
      "- On 2024-03-23, the air quality was 20.0, which indicates that the air quality was unhealthy for sensitive groups, similar to the day before. It may have been safe for most people to go outside, but it's best to check local air quality advisories for updates.\n"
     ]
    }
   ],
   "source": [
    "QUESTION11 = \"When and what was the air quality like last week?\"\n",
    "\n",
    "response11 = generate_response(\n",
    "    QUESTION11, \n",
    "    feature_view, \n",
    "    model_llm,\n",
    "    tokenizer,\n",
    "    model_air_quality,\n",
    "    llm_chain,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "print(response11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3136fb96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished: Reading data from Hopsworks, using ArrowFlight (0.89s) \n",
      "üóìÔ∏è Today's date: Saturday, 2024-03-23\n",
      "üìñ Air Quality Measurements:\n",
      "Date: 2024-01-10; Air Quality: 9.0\n",
      "Date: 2024-01-11; Air Quality: 8.0\n",
      "Date: 2024-01-12; Air Quality: 9.0\n",
      "Date: 2024-01-13; Air Quality: 14.0\n",
      "Date: 2024-01-14; Air Quality: 13.0\n",
      "Date: 2024-01-15; Air Quality: 8.0\n",
      "\n",
      "The minimum air quality from 2024-01-10 to 2024-01-14 was on 2024-01-15, with an air quality of 8.0. This indicates that the air quality on that day was generally good, and it may have been safe for most people to go outside. However, it's always a good idea to check local air quality advisories and take precautions if you have respiratory sensitivities.\n"
     ]
    }
   ],
   "source": [
    "QUESTION12 = \"When and what was the minimum air quality from 2024-01-10 till 2024-01-14?\"\n",
    "\n",
    "response12 = generate_response(\n",
    "    QUESTION12, \n",
    "    feature_view, \n",
    "    model_llm, \n",
    "    tokenizer, \n",
    "    model_air_quality, \n",
    "    llm_chain,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "print(response12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9b8a0dfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished: Reading data from Hopsworks, using ArrowFlight (0.89s) \n",
      "üóìÔ∏è Today's date: Saturday, 2024-03-23\n",
      "üìñ Air Quality Measurements:\n",
      "Date: 2024-03-19; Air Quality: 17.0\n",
      "Date: 2024-03-20; Air Quality: 17.0\n",
      "Date: 2024-03-21; Air Quality: 41.0\n",
      "Date: 2024-03-22; Air Quality: 14.0\n",
      "Date: 2024-03-23; Air Quality: 20.0\n",
      "\n",
      "Last week, the air quality was as follows:\n",
      "\n",
      "- On 2024-03-19, the air quality was 17.0, which indicates that the air quality was generally moderate and it may have been safe for most people to go outside.\n",
      "- On 2024-03-20, the air quality was 17.0, which is the same as the day before. This also indicates moderate air quality and it may have been safe for most people to go outside.\n",
      "- On 2024-03-21, the air quality was 41.0, which indicates that the air quality was very poor and it may have been best to limit outdoor activities, especially if you have respiratory sensitivities.\n",
      "- On 2024-03-22, the air quality was 14.0, which indicates that the air quality was unhealthy for sensitive groups, such as children, the elderly, and those with respiratory conditions. It may have been safe for most people to go outside, but it's best to check local air quality advisories for updates.\n",
      "- On 2024-03-23, the air quality was 20.0, which indicates that the air quality was unhealthy for sensitive groups, similar to the day before. It may have been safe for most people to go outside, but it's best to check local air quality advisories for updates.\n"
     ]
    }
   ],
   "source": [
    "QUESTION2a = \"What was the air quality like last week?\"\n",
    "\n",
    "response2 = generate_response(\n",
    "    QUESTION2a,\n",
    "    feature_view, \n",
    "    model_llm,\n",
    "    tokenizer,\n",
    "    model_air_quality,\n",
    "    llm_chain,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "print(response2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0457f770",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished: Reading data from Hopsworks, using ArrowFlight (0.89s) \n",
      "üóìÔ∏è Today's date: Saturday, 2024-03-23\n",
      "üìñ Air Quality Measurements:\n",
      "Date: 2024-03-22; Air Quality: 14.0\n",
      "\n",
      "Yesterday, the air quality was 20.0, which indicates that the air quality was unhealthy for sensitive groups, similar to the day before. It may have been safe for most people to go outside, but it's best to check local air quality advisories for updates.\n"
     ]
    }
   ],
   "source": [
    "QUESTION2 = \"What was the air quality like yesterday?\"\n",
    "\n",
    "response2 = generate_response(\n",
    "    QUESTION2,\n",
    "    feature_view, \n",
    "    model_llm,\n",
    "    tokenizer,\n",
    "    model_air_quality,\n",
    "    llm_chain,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "print(response2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "be5f5487",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connection closed.\n",
      "Connected. Call `.close()` to terminate connection gracefully.\n",
      "\n",
      "Logged in to project, explore it here https://snurran.hops.works/p/5240\n",
      "Connected. Call `.close()` to terminate connection gracefully.\n",
      "Finished: Reading data from Hopsworks, using ArrowFlight (0.39s) \n",
      "üóìÔ∏è Today's date: Saturday, 2024-03-23\n",
      "üìñ Air Quality Measurements:\n",
      "\n",
      "\n",
      "On 2024-03-20, the air quality was 17.0, which indicates that the air quality was generally moderate and it may have been safe for most people to go outside.\n"
     ]
    }
   ],
   "source": [
    "QUESTION3 = \"What will the air quality be like on 2024-03-20?\"\n",
    "\n",
    "response3 = generate_response(\n",
    "    QUESTION3, \n",
    "    feature_view, \n",
    "    model_llm, \n",
    "    tokenizer,\n",
    "    model_air_quality,\n",
    "    llm_chain,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "print(response3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4a60c8b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connection closed.\n",
      "Connected. Call `.close()` to terminate connection gracefully.\n",
      "\n",
      "Logged in to project, explore it here https://snurran.hops.works/p/5240\n",
      "Connected. Call `.close()` to terminate connection gracefully.\n",
      "Finished: Reading data from Hopsworks, using ArrowFlight (0.38s) \n",
      "üóìÔ∏è Today's date: Saturday, 2024-03-23\n",
      "üìñ Air Quality Measurements:\n",
      "\n",
      "\n",
      "I'm sorry, but I don't have any information about the air quality for the day after tomorrow. Could you please provide me with the date so I can check the air quality for that specific day?\n"
     ]
    }
   ],
   "source": [
    "QUESTION4 = \"What will the air quality be like the day after tomorrow?\"\n",
    "\n",
    "response4 = generate_response(\n",
    "    QUESTION4, \n",
    "    feature_view, \n",
    "    model_llm, \n",
    "    tokenizer, \n",
    "    model_air_quality, \n",
    "    llm_chain,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "print(response4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "05d16519",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connection closed.\n",
      "Connected. Call `.close()` to terminate connection gracefully.\n",
      "\n",
      "Logged in to project, explore it here https://snurran.hops.works/p/5240\n",
      "Connected. Call `.close()` to terminate connection gracefully.\n",
      "Finished: Reading data from Hopsworks, using ArrowFlight (0.41s) \n",
      "üóìÔ∏è Today's date: Saturday, 2024-03-23\n",
      "üìñ Air Quality Measurements:\n",
      "\n",
      "\n",
      "On Sunday, 2024-03-24, the air quality was 20.0, which indicates that the air quality was unhealthy for sensitive groups. It may have been safe for most people to go outside, but it's best to check local air quality advisories for updates.\n"
     ]
    }
   ],
   "source": [
    "QUESTION5 = \"What will the air quality be like this Sunday?\"\n",
    "\n",
    "response5 = generate_response(\n",
    "    QUESTION5, \n",
    "    feature_view, \n",
    "    model_llm, \n",
    "    tokenizer, \n",
    "    model_air_quality, \n",
    "    llm_chain,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "print(response5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b04ae9cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connection closed.\n",
      "Connected. Call `.close()` to terminate connection gracefully.\n",
      "\n",
      "Logged in to project, explore it here https://snurran.hops.works/p/5240\n",
      "Connected. Call `.close()` to terminate connection gracefully.\n",
      "Finished: Reading data from Hopsworks, using ArrowFlight (0.39s) \n",
      "üóìÔ∏è Today's date: Saturday, 2024-03-23\n",
      "üìñ Air Quality Measurements:\n",
      "Date: 2024-03-23 00:00:00; Air Quality: 29.37\n",
      "Date: 2024-03-24 00:00:00; Air Quality: 34.19\n",
      "Date: 2024-03-25 00:00:00; Air Quality: 46.52\n",
      "Date: 2024-03-26 00:00:00; Air Quality: 43.97\n",
      "Date: 2024-03-27 00:00:00; Air Quality: 21.64\n",
      "Date: 2024-03-28 00:00:00; Air Quality: 24.7\n",
      "Date: 2024-03-29 00:00:00; Air Quality: 13.1\n",
      "\n",
      "For the rest of the week, the air quality is expected to be generally unhealthy for sensitive groups, with some days being unhealthy for the general population. It's best to check local air quality advisories for updates and to plan outdoor activities accordingly.\n"
     ]
    }
   ],
   "source": [
    "QUESTION7 = \"What will the air quality be like for the rest of the week?\"\n",
    "\n",
    "response7 = generate_response(\n",
    "    QUESTION7, \n",
    "    feature_view,\n",
    "    model_llm,\n",
    "    tokenizer, \n",
    "    model_air_quality, \n",
    "    llm_chain,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "print(response7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "68e9fb85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connection closed.\n",
      "Connected. Call `.close()` to terminate connection gracefully.\n",
      "\n",
      "Logged in to project, explore it here https://snurran.hops.works/p/5240\n",
      "Connected. Call `.close()` to terminate connection gracefully.\n",
      "Finished: Reading data from Hopsworks, using ArrowFlight (0.38s) \n",
      "üóìÔ∏è Today's date: Saturday, 2024-03-23\n",
      "üìñ Air Quality Measurements:\n",
      "Date: 2024-03-23 00:00:00; Air Quality: 29.37\n",
      "Date: 2024-03-24 00:00:00; Air Quality: 34.19\n",
      "Date: 2024-03-25 00:00:00; Air Quality: 46.52\n",
      "Date: 2024-03-26 00:00:00; Air Quality: 43.97\n",
      "Date: 2024-03-27 00:00:00; Air Quality: 21.64\n",
      "Date: 2024-03-28 00:00:00; Air Quality: 24.7\n",
      "Date: 2024-03-29 00:00:00; Air Quality: 13.1\n",
      "\n",
      "For the rest of the week, the air quality is expected to be generally unhealthy for sensitive groups, with some days being unhealthy for the general population. It's best to check local air quality advisories for updates and to plan outdoor activities accordingly.\n"
     ]
    }
   ],
   "source": [
    "QUESTION = \"Will the air quality be safe or not for the next week?\"\n",
    "\n",
    "response = generate_response(\n",
    "    QUESTION7, \n",
    "    feature_view, \n",
    "    model_llm, \n",
    "    tokenizer,\n",
    "    model_air_quality,\n",
    "    llm_chain,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "67944ef5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connection closed.\n",
      "Connected. Call `.close()` to terminate connection gracefully.\n",
      "\n",
      "Logged in to project, explore it here https://snurran.hops.works/p/5240\n",
      "Connected. Call `.close()` to terminate connection gracefully.\n",
      "Finished: Reading data from Hopsworks, using ArrowFlight (0.42s) \n",
      "üóìÔ∏è Today's date: Saturday, 2024-03-23\n",
      "üìñ Air Quality Measurements:\n",
      "\n",
      "\n",
      "On Monday, 2024-03-25, the air quality was 30.0, which indicates that the air quality was unhealthy for sensitive groups. It may have been safe for most people to go outside, but it's best to check local air quality advisories for updates.\n"
     ]
    }
   ],
   "source": [
    "QUESTION = \"Is tomorrow's air quality level dangerous?\"\n",
    "\n",
    "response = generate_response(\n",
    "    QUESTION, \n",
    "    feature_view, \n",
    "    model_llm, \n",
    "    tokenizer,\n",
    "    model_air_quality, \n",
    "    llm_chain,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b7ae416d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üóìÔ∏è Today's date: Saturday, 2024-03-23\n",
      "üìñ \n",
      "\n",
      "Of course! Here are the different air quality levels and their descriptions:\n",
      "\n",
      "1. Good (0-50): The air quality is considered good, and it is generally safe for everyone to be outside.\n",
      "2. Moderate (51-100): The air quality is acceptable, but sensitive groups like children, the elderly, and those with respiratory issues may experience some discomfort.\n",
      "3. Unhealthy for Sensitive Groups (101-150): The air quality is unhealthy for sensitive groups, and everyone else should limit prolonged outdoor exertion.\n",
      "4. Unhealthy (151-200): The air quality is unhealthy for the general population, and everyone should limit prolonged outdoor exertion.\n",
      "5. Very Unhealthy (201-300): The air quality is very unhealthy, and everyone should avoid prolonged outdoor exertion.\n",
      "6. Hazardous (>300): The air quality is hazardous and poses a serious health risk to everyone, and all outdoor activities should be avoided.\n",
      "\n",
      "These levels are based on the Air Quality Index (AQI), which takes into account several air pollutants, including ground-level ozone and particle pollution.\n"
     ]
    }
   ],
   "source": [
    "QUESTION = \"Can you please explain different air quality levels?\"\n",
    "\n",
    "response = generate_response(\n",
    "    QUESTION, \n",
    "    feature_view, \n",
    "    model_llm, \n",
    "    tokenizer,\n",
    "    model_air_quality, \n",
    "    llm_chain,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5bbbe102",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-03-23 18:51:12,356 INFO: HTTP Request: GET https://api.gradio.app/gradio-messaging/en \"HTTP/1.1 200 OK\"\n"
     ]
    }
   ],
   "source": [
    "import gradio as gr\n",
    "from transformers import pipeline\n",
    "import numpy as np\n",
    "import hopsworks\n",
    "from xgboost import XGBRegressor\n",
    "from functions.llm_chain import load_model, get_llm_chain, generate_response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6e770a88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7860\n",
      "2024-03-23 18:51:14,155 INFO: HTTP Request: GET http://127.0.0.1:7860/startup-events \"HTTP/1.1 200 OK\"\n",
      "2024-03-23 18:51:14,231 INFO: HTTP Request: GET https://checkip.amazonaws.com/ \"HTTP/1.1 200 \"\n",
      "2024-03-23 18:51:14,638 INFO: HTTP Request: GET https://api.gradio.app/pkg-version \"HTTP/1.1 200 OK\"\n",
      "2024-03-23 18:51:15,001 INFO: HTTP Request: POST https://api.gradio.app/gradio-initiated-analytics/ \"HTTP/1.1 200 OK\"\n",
      "2024-03-23 18:51:16,211 INFO: HTTP Request: HEAD http://127.0.0.1:7860/ \"HTTP/1.1 200 OK\"\n",
      "2024-03-23 18:51:17,289 INFO: HTTP Request: GET https://api.gradio.app/v2/tunnel-request \"HTTP/1.1 200 OK\"\n",
      "Running on public URL: https://c674f22c8da86c7674.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n",
      "2024-03-23 18:51:18,652 INFO: HTTP Request: HEAD https://c674f22c8da86c7674.gradio.live \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://c674f22c8da86c7674.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-03-23 18:51:19,374 INFO: HTTP Request: POST https://api.gradio.app/gradio-launched-telemetry/ \"HTTP/1.1 200 OK\"\n",
      "Connection closed.\n",
      "Connected. Call `.close()` to terminate connection gracefully.\n",
      "\n",
      "Logged in to project, explore it here https://snurran.hops.works/p/5240\n",
      "Connected. Call `.close()` to terminate connection gracefully.\n",
      "Finished: Reading data from Hopsworks, using ArrowFlight (0.43s) \n",
      "Connection closed.\n",
      "Connected. Call `.close()` to terminate connection gracefully.\n",
      "\n",
      "Logged in to project, explore it here https://snurran.hops.works/p/5240\n",
      "Connected. Call `.close()` to terminate connection gracefully.\n",
      "Finished: Reading data from Hopsworks, using ArrowFlight (0.42s) \n",
      "Connection closed.\n",
      "Connected. Call `.close()` to terminate connection gracefully.\n",
      "\n",
      "Logged in to project, explore it here https://snurran.hops.works/p/5240\n",
      "Connected. Call `.close()` to terminate connection gracefully.\n",
      "Finished: Reading data from Hopsworks, using ArrowFlight (0.42s) \n",
      "Connection closed.\n",
      "Connected. Call `.close()` to terminate connection gracefully.\n",
      "\n",
      "Logged in to project, explore it here https://snurran.hops.works/p/5240\n",
      "Connected. Call `.close()` to terminate connection gracefully.\n",
      "Finished: Reading data from Hopsworks, using ArrowFlight (0.43s) \n"
     ]
    }
   ],
   "source": [
    "# Initialize the ASR pipeline\n",
    "transcriber = pipeline(\"automatic-speech-recognition\", model=\"openai/whisper-base.en\")\n",
    "\n",
    "def transcribe(audio):\n",
    "    sr, y = audio\n",
    "    y = y.astype(np.float32)\n",
    "    if y.ndim > 1 and y.shape[1] > 1:\n",
    "        y = np.mean(y, axis=1)\n",
    "    y /= np.max(np.abs(y))\n",
    "    return transcriber({\"sampling_rate\": sr, \"raw\": y})[\"text\"]\n",
    "\n",
    "def generate_query_response(user_query):\n",
    "    response = generate_response(\n",
    "        user_query,\n",
    "        feature_view,\n",
    "        model_llm,\n",
    "        tokenizer,\n",
    "        model_air_quality,\n",
    "        llm_chain,\n",
    "        verbose=False,\n",
    "    )\n",
    "    return response\n",
    "\n",
    "def handle_input(text_input=None, audio_input=None):\n",
    "    if audio_input is not None:\n",
    "        user_query = transcribe(audio_input)\n",
    "    else:\n",
    "        user_query = text_input\n",
    "    \n",
    "    if user_query:\n",
    "        return generate_query_response(user_query)\n",
    "    else:\n",
    "        return \"Please provide input either via text or voice.\"\n",
    "\n",
    "iface = gr.Interface(\n",
    "    fn=handle_input,\n",
    "    inputs=[gr.Textbox(placeholder=\"Type here or use voice input...\"), gr.Audio()],\n",
    "    outputs=\"text\",\n",
    "    title=\"üå§Ô∏è AirQuality AI Assistant üí¨\",\n",
    "    description=\"Ask your questions about air quality or use your voice to interact.\"\n",
    ")\n",
    "\n",
    "iface.launch(share=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a196d7b1",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
